{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TsL9ZpTsM-1"
      },
      "outputs": [],
      "source": [
        "# DataHandler Class for Dataset Splitting and Saving\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DataHandler:\n",
        "    def __init__(self, file_path, label_column=\"Label\"):\n",
        "        self.file_path = file_path\n",
        "        self.label_column = label_column\n",
        "        self.df = None\n",
        "        self.labeled_df = None\n",
        "        self.unlabeled_df = None\n",
        "        self.unlabeled_train_df = None\n",
        "        self.unlabeled_test_df = None\n",
        "        self.train_labels = None\n",
        "        self.test_labels = None\n",
        "\n",
        "    def load_dataset(self):\n",
        "        self.df = pd.read_csv(self.file_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {self.df.shape}\")\n",
        "        print(f\"Columns: {list(self.df.columns)}\")\n",
        "\n",
        "    def split_labeled_unlabeled(self, labeled_fraction=0.05):\n",
        "        np.random.seed(42)\n",
        "        self.df = self.df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "        self.labeled_df = self.df.sample(frac=labeled_fraction, random_state=42)\n",
        "        self.unlabeled_df = self.df.drop(self.labeled_df.index)\n",
        "        print(f\"Labeled Data Shape: {self.labeled_df.shape}\")\n",
        "        print(f\"Unlabeled Data Shape: {self.unlabeled_df.shape}\")\n",
        "\n",
        "    def split_unlabeled_train_test(self, test_size=0.10):\n",
        "        original_labels = self.unlabeled_df[self.label_column]\n",
        "        unlabeled_df_no_label = self.unlabeled_df.drop(columns=[self.label_column])\n",
        "\n",
        "        self.unlabeled_train_df, self.unlabeled_test_df, self.train_labels, self.test_labels = train_test_split(\n",
        "            unlabeled_df_no_label, original_labels, test_size=test_size, random_state=42\n",
        "        )\n",
        "\n",
        "        print(f\"Unlabeled Train Shape: {self.unlabeled_train_df.shape}\")\n",
        "        print(f\"Unlabeled Test Shape: {self.unlabeled_test_df.shape}\")\n",
        "        return self.unlabeled_train_df, self.unlabeled_test_df, self.train_labels, self.test_labels\n",
        "\n",
        "    def save_datasets(self):\n",
        "        self.labeled_df.to_csv(\"labeled_data.csv\", index=False)\n",
        "        self.unlabeled_train_df.to_csv(\"unlabeled_train_data.csv\", index=False)\n",
        "        self.unlabeled_test_df.to_csv(\"unlabeled_test_data.csv\", index=False)\n",
        "        self.train_labels.to_csv(\"unlabeled_train_true_labels.csv\", index=False)\n",
        "        self.test_labels.to_csv(\"unlabeled_test_true_labels.csv\", index=False)\n",
        "        print(\"Datasets saved successfully!\")\n",
        "\n",
        "    def prepare_labeled_data_for_training(self, validation_split=0.20):\n",
        "        X = self.labeled_df.drop(columns=[self.label_column])\n",
        "        y = self.labeled_df[self.label_column]\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=validation_split, random_state=42\n",
        "        )\n",
        "        print(f\"Training Data Shape: {X_train.shape}\")\n",
        "        print(f\"Validation Data Shape: {X_val.shape}\")\n",
        "        return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "class TeacherModel:\n",
        "    def __init__(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.models = self._initialize_models()\n",
        "        self.trained_models = {}\n",
        "\n",
        "    def _initialize_models(self):\n",
        "        return {\n",
        "            \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
        "            \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "            \"Bagging\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42),\n",
        "            \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "        }\n",
        "\n",
        "    def train_with_cross_validation(self, folds=10):\n",
        "        best_scores = {}\n",
        "        for name, model in self.models.items():\n",
        "            scores = cross_val_score(model, self.X_train, self.y_train, cv=folds, scoring='accuracy')\n",
        "            avg_score = scores.mean()\n",
        "            best_scores[name] = avg_score\n",
        "            print(f\"{name} - Avg Accuracy (10-fold CV): {avg_score:.4f}\")\n",
        "\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            self.trained_models[name] = model\n",
        "        return best_scores\n",
        "\n",
        "    def generate_pseudo_labels(self, unlabeled_df, model_name):\n",
        "        model = self.trained_models.get(model_name)\n",
        "        if model:\n",
        "            preds = model.predict(unlabeled_df)\n",
        "            return preds\n",
        "        else:\n",
        "            print(f\"Model {model_name} not found!\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "RfWgRUX9sasC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "class StudentModel:\n",
        "    def __init__(self, pseudo_labels_df, true_labels):\n",
        "        self.X_train = pseudo_labels_df  # Features from pseudo labels\n",
        "        self.y_train = true_labels       # True labels for the test set\n",
        "        self.models = self._initialize_models()\n",
        "        self.trained_models = {}\n",
        "        self.results = {}\n",
        "\n",
        "    def _initialize_models(self):\n",
        "        return {\n",
        "            \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
        "            \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "            \"Bagging\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42),\n",
        "            \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "        }\n",
        "\n",
        "    def train_and_evaluate(self, X_test, y_test):\n",
        "        for name, model in self.models.items():\n",
        "            # Cross-validation on pseudo-labeled data\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=10, scoring='accuracy')\n",
        "            avg_cv_score = cv_scores.mean()\n",
        "\n",
        "            # Train on all pseudo-labeled data\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            self.trained_models[name] = model\n",
        "\n",
        "            # Evaluate on true labeled test data\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Metrics\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            precision = precision_score(y_test, y_pred, average='weighted')\n",
        "            recall = recall_score(y_test, y_pred, average='weighted')\n",
        "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "            # Store results\n",
        "            self.results[name] = {\n",
        "                \"Cross-Validation Accuracy\": avg_cv_score,\n",
        "                \"Test Accuracy\": acc,\n",
        "                \"Precision\": precision,\n",
        "                \"Recall\": recall,\n",
        "                \"F1-Score\": f1\n",
        "            }\n",
        "\n",
        "    def print_results(self, teacher_model_name):\n",
        "        print(f\"\\nResults for Teacher Model: {teacher_model_name}\")\n",
        "        for student_name, metrics in self.results.items():\n",
        "            print(f\"\\nStudent Model: {student_name}\")\n",
        "            for metric_name, value in metrics.items():\n",
        "                print(f\"{metric_name}: {value:.4f}\")\n"
      ],
      "metadata": {
        "id": "puUtdnwYxO5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from data_handler import DataHandler\n",
        "# from teacher_model import TeacherModel\n",
        "# from student_model import StudentModel\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Initialize DataHandler\n",
        "data_handler = DataHandler(\"train_test_networkP.csv\")\n",
        "\n",
        "# Step 2: Load and split dataset\n",
        "data_handler.load_dataset()\n",
        "data_handler.split_labeled_unlabeled()\n",
        "unlabeled_train, unlabeled_test, train_labels, test_labels = data_handler.split_unlabeled_train_test()\n",
        "\n",
        "# Step 3: Save datasets automatically\n",
        "data_handler.save_datasets()\n",
        "\n",
        "# Step 4: Prepare labeled data for training (Train/Validation Split)\n",
        "X_train, X_val, y_train, y_val = data_handler.prepare_labeled_data_for_training()\n",
        "\n",
        "# Step 5: Train Teacher Models with 10-Fold Cross-Validation\n",
        "teacher = TeacherModel(X_train, y_train)\n",
        "teacher_scores = teacher.train_with_cross_validation()\n",
        "\n",
        "# Step 6: Train Student Models with pseudo-labels from each teacher model\n",
        "for teacher_model_name in teacher.trained_models.keys():\n",
        "    # Generate pseudo labels\n",
        "    pseudo_labels = teacher.generate_pseudo_labels(data_handler.unlabeled_train_df, teacher_model_name)\n",
        "\n",
        "    # Convert pseudo labels to Series (1D data for training)\n",
        "    pseudo_labels_series = pd.Series(pseudo_labels, name='pseudo_label')\n",
        "\n",
        "    # Initialize and Train Student Models\n",
        "    student_model = StudentModel(\n",
        "        data_handler.unlabeled_train_df,  # Original features for training\n",
        "        pseudo_labels_series              # Pseudo labels as target values\n",
        "    )\n",
        "\n",
        "    # Train and evaluate the student models\n",
        "    student_model.train_and_evaluate(data_handler.unlabeled_test_df, test_labels)\n",
        "\n",
        "    # Print results for each teacher-student model pair\n",
        "    student_model.print_results(teacher_model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "x9RWRAKbsgV3",
        "outputId": "4da3f807-15a2-4791-f4f7-97a8d2c499ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Shape: (211043, 31)\n",
            "Columns: ['proto', 'service', 'duration', 'src_bytes', 'dst_bytes', 'conn_state', 'missed_bytes', 'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes', 'dns_query', 'dns_qclass', 'dns_qtype', 'dns_rcode', 'dns_AA', 'dns_RD', 'dns_RA', 'dns_rejected', 'ssl_version', 'ssl_cipher', 'ssl_resumed', 'ssl_established', 'ssl_subject', 'http_trans_depth', 'http_method', 'http_version', 'http_request_body_len', 'http_response_body_len', 'http_status_code', 'Label']\n",
            "Labeled Data Shape: (10552, 31)\n",
            "Unlabeled Data Shape: (200491, 31)\n",
            "Unlabeled Train Shape: (180441, 30)\n",
            "Unlabeled Test Shape: (20050, 30)\n",
            "Datasets saved successfully!\n",
            "Training Data Shape: (8441, 30)\n",
            "Validation Data Shape: (2111, 30)\n",
            "XGBoost - Avg Accuracy (10-fold CV): 0.9964\n",
            "Random Forest - Avg Accuracy (10-fold CV): 0.9968\n",
            "Decision Tree - Avg Accuracy (10-fold CV): 0.9948\n",
            "Bagging - Avg Accuracy (10-fold CV): 0.9954\n",
            "AdaBoost - Avg Accuracy (10-fold CV): 0.9852\n",
            "\n",
            "Results for Teacher Model: XGBoost\n",
            "\n",
            "Student Model: XGBoost\n",
            "Cross-Validation Accuracy: 0.9996\n",
            "Test Accuracy: 0.9962\n",
            "Precision: 0.9962\n",
            "Recall: 0.9962\n",
            "F1-Score: 0.9962\n",
            "\n",
            "Student Model: Random Forest\n",
            "Cross-Validation Accuracy: 0.9994\n",
            "Test Accuracy: 0.9963\n",
            "Precision: 0.9963\n",
            "Recall: 0.9963\n",
            "F1-Score: 0.9963\n",
            "\n",
            "Student Model: Decision Tree\n",
            "Cross-Validation Accuracy: 0.9993\n",
            "Test Accuracy: 0.9960\n",
            "Precision: 0.9960\n",
            "Recall: 0.9960\n",
            "F1-Score: 0.9960\n",
            "\n",
            "Student Model: Bagging\n",
            "Cross-Validation Accuracy: 0.9994\n",
            "Test Accuracy: 0.9962\n",
            "Precision: 0.9962\n",
            "Recall: 0.9962\n",
            "F1-Score: 0.9962\n",
            "\n",
            "Student Model: AdaBoost\n",
            "Cross-Validation Accuracy: 0.9874\n",
            "Test Accuracy: 0.9876\n",
            "Precision: 0.9876\n",
            "Recall: 0.9876\n",
            "F1-Score: 0.9875\n",
            "\n",
            "Results for Teacher Model: Random Forest\n",
            "\n",
            "Student Model: XGBoost\n",
            "Cross-Validation Accuracy: 0.9997\n",
            "Test Accuracy: 0.9976\n",
            "Precision: 0.9976\n",
            "Recall: 0.9976\n",
            "F1-Score: 0.9976\n",
            "\n",
            "Student Model: Random Forest\n",
            "Cross-Validation Accuracy: 0.9998\n",
            "Test Accuracy: 0.9975\n",
            "Precision: 0.9975\n",
            "Recall: 0.9975\n",
            "F1-Score: 0.9975\n",
            "\n",
            "Student Model: Decision Tree\n",
            "Cross-Validation Accuracy: 0.9996\n",
            "Test Accuracy: 0.9975\n",
            "Precision: 0.9975\n",
            "Recall: 0.9975\n",
            "F1-Score: 0.9975\n",
            "\n",
            "Student Model: Bagging\n",
            "Cross-Validation Accuracy: 0.9997\n",
            "Test Accuracy: 0.9976\n",
            "Precision: 0.9976\n",
            "Recall: 0.9976\n",
            "F1-Score: 0.9976\n",
            "\n",
            "Student Model: AdaBoost\n",
            "Cross-Validation Accuracy: 0.9875\n",
            "Test Accuracy: 0.9840\n",
            "Precision: 0.9840\n",
            "Recall: 0.9840\n",
            "F1-Score: 0.9840\n",
            "\n",
            "Results for Teacher Model: Decision Tree\n",
            "\n",
            "Student Model: XGBoost\n",
            "Cross-Validation Accuracy: 0.9995\n",
            "Test Accuracy: 0.9956\n",
            "Precision: 0.9956\n",
            "Recall: 0.9956\n",
            "F1-Score: 0.9956\n",
            "\n",
            "Student Model: Random Forest\n",
            "Cross-Validation Accuracy: 0.9994\n",
            "Test Accuracy: 0.9956\n",
            "Precision: 0.9956\n",
            "Recall: 0.9956\n",
            "F1-Score: 0.9956\n",
            "\n",
            "Student Model: Decision Tree\n",
            "Cross-Validation Accuracy: 0.9998\n",
            "Test Accuracy: 0.9956\n",
            "Precision: 0.9956\n",
            "Recall: 0.9956\n",
            "F1-Score: 0.9956\n",
            "\n",
            "Student Model: Bagging\n",
            "Cross-Validation Accuracy: 0.9998\n",
            "Test Accuracy: 0.9955\n",
            "Precision: 0.9955\n",
            "Recall: 0.9955\n",
            "F1-Score: 0.9955\n",
            "\n",
            "Student Model: AdaBoost\n",
            "Cross-Validation Accuracy: 0.9849\n",
            "Test Accuracy: 0.9846\n",
            "Precision: 0.9846\n",
            "Recall: 0.9846\n",
            "F1-Score: 0.9846\n",
            "\n",
            "Results for Teacher Model: Bagging\n",
            "\n",
            "Student Model: XGBoost\n",
            "Cross-Validation Accuracy: 0.9996\n",
            "Test Accuracy: 0.9963\n",
            "Precision: 0.9963\n",
            "Recall: 0.9963\n",
            "F1-Score: 0.9963\n",
            "\n",
            "Student Model: Random Forest\n",
            "Cross-Validation Accuracy: 0.9995\n",
            "Test Accuracy: 0.9962\n",
            "Precision: 0.9962\n",
            "Recall: 0.9962\n",
            "F1-Score: 0.9962\n",
            "\n",
            "Student Model: Decision Tree\n",
            "Cross-Validation Accuracy: 0.9997\n",
            "Test Accuracy: 0.9961\n",
            "Precision: 0.9961\n",
            "Recall: 0.9961\n",
            "F1-Score: 0.9961\n",
            "\n",
            "Student Model: Bagging\n",
            "Cross-Validation Accuracy: 0.9997\n",
            "Test Accuracy: 0.9962\n",
            "Precision: 0.9962\n",
            "Recall: 0.9962\n",
            "F1-Score: 0.9962\n",
            "\n",
            "Student Model: AdaBoost\n",
            "Cross-Validation Accuracy: 0.9876\n",
            "Test Accuracy: 0.9838\n",
            "Precision: 0.9838\n",
            "Recall: 0.9838\n",
            "F1-Score: 0.9838\n",
            "\n",
            "Results for Teacher Model: AdaBoost\n",
            "\n",
            "Student Model: XGBoost\n",
            "Cross-Validation Accuracy: 0.9998\n",
            "Test Accuracy: 0.9838\n",
            "Precision: 0.9838\n",
            "Recall: 0.9838\n",
            "F1-Score: 0.9838\n",
            "\n",
            "Student Model: Random Forest\n",
            "Cross-Validation Accuracy: 0.9999\n",
            "Test Accuracy: 0.9837\n",
            "Precision: 0.9837\n",
            "Recall: 0.9837\n",
            "F1-Score: 0.9837\n",
            "\n",
            "Student Model: Decision Tree\n",
            "Cross-Validation Accuracy: 0.9999\n",
            "Test Accuracy: 0.9837\n",
            "Precision: 0.9837\n",
            "Recall: 0.9837\n",
            "F1-Score: 0.9837\n",
            "\n",
            "Student Model: Bagging\n",
            "Cross-Validation Accuracy: 0.9999\n",
            "Test Accuracy: 0.9837\n",
            "Precision: 0.9837\n",
            "Recall: 0.9837\n",
            "F1-Score: 0.9837\n",
            "\n",
            "Student Model: AdaBoost\n",
            "Cross-Validation Accuracy: 0.9978\n",
            "Test Accuracy: 0.9839\n",
            "Precision: 0.9839\n",
            "Recall: 0.9839\n",
            "F1-Score: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgsqMA0HxLbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}